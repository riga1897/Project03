"""
–ú–æ–¥—É–ª—å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ API –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
"""

import json
import os
import time
from typing import Dict, List
from datetime import datetime, timedelta

from src.api import HHApi
from src.database import DatabaseSetup, DBManager


class DataLoader:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ API HeadHunter
    –∏ –∏—Ö –∑–∞–≥—Ä—É–∑–∫—É –≤ PostgreSQL –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
    """

    def __init__(self, db_manager: DBManager = None, api: HHApi = None) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö."""
        self.api: HHApi = api or HHApi()
        self.db_setup: DatabaseSetup = DatabaseSetup()
        self.db_manager: DBManager = db_manager or DBManager()
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∫—ç—à–∞ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        self.cache_dir: str = os.path.join(project_root, "cache")
        os.makedirs(self.cache_dir, exist_ok=True)
        self.cache_file: str = os.path.join(self.cache_dir, "hh_data_cache.json")
        self.cache_meta_file: str = os.path.join(self.cache_dir, "cache_metadata.json")
        self.cache_expiry_hours: int = 24  # –ö—ç—à –¥–µ–π—Å—Ç–≤—É–µ—Ç 24 —á–∞—Å–∞

    def show_progress_bar(self, current: int, total: int, prefix: str = "", suffix: str = "", length: int = 40) -> None:
        """
        –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –≤ –∫–æ–Ω—Å–æ–ª–∏.

        Args:
            current: –¢–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
            total: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            prefix: –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            suffix: –°—É—Ñ—Ñ–∏–∫—Å –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞  
            length: –î–ª–∏–Ω–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
        """
        if total == 0:
            return

        percent = current / total
        filled_length = int(length * percent)
        bar = '‚ñà' * filled_length + '‚ñë' * (length - filled_length)

        print(f'\r{prefix} |{bar}| {current}/{total} ({percent:.1%}) {suffix}', end='', flush=True)

        if current == total:
            print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ –∫–æ–Ω—Ü–µ

    def is_cache_valid(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –ª–∏ –∫—ç—à.

        Returns:
            bool: True –µ—Å–ª–∏ –∫—ç—à –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω
        """
        if not os.path.exists(self.cache_file) or not os.path.exists(self.cache_meta_file):
            return False

        try:
            with open(self.cache_meta_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)

            cache_time = datetime.fromisoformat(metadata.get('created_at', ''))
            expiry_time = cache_time + timedelta(hours=self.cache_expiry_hours)

            is_valid = datetime.now() < expiry_time

            if is_valid:
                time_left = expiry_time - datetime.now()
                hours_left = int(time_left.total_seconds() / 3600)
                print(f"üìÇ –ö—ç—à –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –µ—â–µ {hours_left} —á–∞—Å–æ–≤")
            else:
                print("‚è∞ –ö—ç—à —É—Å—Ç–∞—Ä–µ–ª, –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")

            return is_valid

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫—ç—à–∞: {e}")
            return False

    def save_cache_metadata(self, companies_count: int, vacancies_count: int) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫—ç—à–∞.

        Args:
            companies_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–∞–Ω–∏–π
            vacancies_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π
        """
        metadata = {
            'created_at': datetime.now().isoformat(),
            'companies_count': companies_count,
            'vacancies_count': vacancies_count,
            'expiry_hours': self.cache_expiry_hours
        }

        try:
            with open(self.cache_meta_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")

    def load_cache_metadata(self) -> Dict:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫—ç—à–∞.

        Returns:
            Dict: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫—ç—à–∞
        """
        try:
            if os.path.exists(self.cache_meta_file):
                with open(self.cache_meta_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")

        return {}

    def setup_database(self) -> bool:
        """
        –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (—Å–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã).

        Returns:
            bool: True –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
        """
        print("\nüì¶ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")

        if not self.db_setup.test_connection():
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ë–î")
            return False

        if not self.db_setup.create_tables():
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã")
            return False

        return True

    def collect_data(self, use_cache: bool = True, keyword: str = None, period: int = 15) -> Dict[str, List[Dict]]:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö, —Ñ–∞–π–ª–æ–≤–æ–≥–æ –∫—ç—à–∞ –∏ API –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ.

        Args:
            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞
            period: –ü–µ—Ä–∏–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–π –≤ –¥–Ω—è—Ö

        Returns:
            Dict[str, List[Dict]]: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–º–ø–∞–Ω–∏—è–º–∏ –∏ –≤–∞–∫–∞–Ω—Å–∏—è–º–∏
        """
        # 1. –°–Ω–∞—á–∞–ª–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        print("\nüì¶ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        if not self.setup_database():
            print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –Ω–µ—ë")

        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª–æ–≤—ã–π –∫—ç—à —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω —Å–≤–µ–∂–∏–π
        if use_cache and self._is_cache_valid():
            print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–≥–æ –∫—ç—à–∞: {self.cache_file}")
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ –∫—ç—à–∞: {len(data.get('companies', []))} –∫–æ–º–ø–∞–Ω–∏–π, {len(data.get('vacancies', []))} –≤–∞–∫–∞–Ω—Å–∏–π")
                return data
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫—ç—à–∞: {e}")
                print("üîÑ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ –±–∞–∑—ã –∏ API...")

        # 3. –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è (–±–∞–∑–æ–≤—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏—Å—Ç–∏–Ω—ã)
        print("\nüóÉÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã –≤ –∫—ç—à...")
        db_cache = self.db_manager.get_database_cache(self.api.target_companies)
        existing_vacancy_ids = self.db_manager.get_existing_vacancy_ids(self.api.target_companies)
        existing_company_ids = self.db_manager.get_existing_company_ids()

        print(f"üìä –í –±–∞–∑–µ –Ω–∞–π–¥–µ–Ω–æ: {len(db_cache.get('companies', []))} –∫–æ–º–ø–∞–Ω–∏–π, {len(db_cache.get('vacancies', []))} –≤–∞–∫–∞–Ω—Å–∏–π")

        # 4. –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ API
        companies_to_fetch = [cid for cid in self.api.target_companies if cid not in existing_company_ids]
        print(f"üÜï –ù—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ API: {len(companies_to_fetch)} –Ω–æ–≤—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π")

        # 5. –ü–æ–ª—É—á–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ API (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        if companies_to_fetch or len(db_cache.get('vacancies', [])) == 0:
            print(f"\nüåê –ü–æ–ª—É—á–µ–Ω–∏–µ {'–Ω–æ–≤—ã—Ö ' if db_cache.get('vacancies') else ''}–¥–∞–Ω–Ω—ã—Ö –∏–∑ API HeadHunter...")
            if existing_vacancy_ids:
                print(f"‚ö° –ë—É–¥—É—Ç –∏—Å–∫–ª—é—á–µ–Ω—ã {len(existing_vacancy_ids)} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π")
            
            api_data = self.api.collect_data(keyword=keyword, period=period, existing_vacancy_ids=existing_vacancy_ids)
        else:
            print(f"\n‚úÖ –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ, API –∑–∞–ø—Ä–æ—Å—ã –Ω–µ –Ω—É–∂–Ω—ã")
            api_data = {'companies': [], 'vacancies': []}

        # 6. –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –∏ API
        combined_data = self._merge_data(db_cache, api_data)
        
        # 7. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª–æ–≤—ã–π –∫—ç—à
        self._save_to_cache(combined_data)

        print(f"‚úÖ –ò—Ç–æ–≥–æ —Å–æ–±—Ä–∞–Ω–æ: {len(combined_data.get('companies', []))} –∫–æ–º–ø–∞–Ω–∏–π, {len(combined_data.get('vacancies', []))} –≤–∞–∫–∞–Ω—Å–∏–π")

        return combined_data

    def _merge_data(self, db_data: Dict[str, List[Dict]], api_data: Dict[str, List[Dict]]) -> Dict[str, List[Dict]]:
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –∏ API, –∏–∑–±–µ–≥–∞—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è.

        Args:
            db_data: –î–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            api_data: –î–∞–Ω–Ω—ã–µ –∏–∑ API

        Returns:
            Dict[str, List[Dict]]: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–º–ø–∞–Ω–∏–∏, –∏–∑–±–µ–≥–∞—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ ID
        db_company_ids = {comp.get('id') for comp in db_data.get('companies', [])}
        api_companies = [comp for comp in api_data.get('companies', []) 
                        if comp.get('id') not in db_company_ids]
        
        combined_companies = list(db_data.get('companies', [])) + api_companies

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏, –∏–∑–±–µ–≥–∞—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ ID
        db_vacancy_ids = {vac.get('id') for vac in db_data.get('vacancies', [])}
        api_vacancies = [vac for vac in api_data.get('vacancies', []) 
                        if vac.get('id') not in db_vacancy_ids]
        
        combined_vacancies = list(db_data.get('vacancies', [])) + api_vacancies

        if api_companies or api_vacancies:
            print(f"üîÑ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö: +{len(api_companies)} –∫–æ–º–ø–∞–Ω–∏–π, +{len(api_vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ API")

        return {
            'companies': combined_companies,
            'vacancies': combined_vacancies
        }

    def _is_cache_valid(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∫—ç—à–∞.

        Returns:
            bool: True –µ—Å–ª–∏ –∫—ç—à —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –≤–∞–ª–∏–¥–µ–Ω
        """
        if not os.path.exists(self.cache_file):
            return False

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç —Ñ–∞–π–ª–∞ (–∫—ç—à –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω 24 —á–∞—Å–∞)
            import time
            file_age = time.time() - os.path.getmtime(self.cache_file)
            if file_age > 24 * 60 * 60:  # 24 —á–∞—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
                print("‚è∞ –ö—ç—à —É—Å—Ç–∞—Ä–µ–ª (—Å—Ç–∞—Ä—à–µ 24 —á–∞—Å–æ–≤)")
                return False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if not isinstance(data, dict) or 'companies' not in data or 'vacancies' not in data:
                    print("üîç –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫—ç—à–∞")
                    return False

            return True
        except Exception:
            return False

    def _save_to_cache(self, data: Dict[str, List[Dict]]) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏.

        Args:
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        try:
            from datetime import datetime

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            cache_data = {
                'metadata': {
                    'created_at': datetime.now().isoformat(),
                    'companies_count': len(data.get('companies', [])),
                    'vacancies_count': len(data.get('vacancies', []))
                },
                'companies': data.get('companies', []),
                'vacancies': data.get('vacancies', [])
            }

            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2, default=str)

            print(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫—ç—à: {self.cache_file}")
            print(f"üìä –ö—ç—à —Å–æ–¥–µ—Ä–∂–∏—Ç: {cache_data['metadata']['companies_count']} –∫–æ–º–ø–∞–Ω–∏–π, {cache_data['metadata']['vacancies_count']} –≤–∞–∫–∞–Ω—Å–∏–π")

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {e}")

    def load_to_database(self, data: Dict[str, List[Dict]]) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

        Args:
            data: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–º–ø–∞–Ω–∏—è–º–∏ –∏ –≤–∞–∫–∞–Ω—Å–∏—è–º–∏

        Returns:
            bool: True –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
        """
        print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ PostgreSQL...")

        companies = data.get('companies', [])
        vacancies = data.get('vacancies', [])

        if not companies or not vacancies:
            print("‚úó –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
            return False

        print(f"üìä –î–∞–Ω–Ω—ã–µ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏:")
        print(f"  ‚Ä¢ –ö–æ–º–ø–∞–Ω–∏–π: {len(companies)}")
        print(f"  ‚Ä¢ –í–∞–∫–∞–Ω—Å–∏–π: {len(vacancies)}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–º–ø–∞–Ω–∏–∏
        if not self.db_manager.insert_companies(companies):
            print("‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–º–ø–∞–Ω–∏–π")
            return False

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏
        if not self.db_manager.insert_vacancies(vacancies):
            print("‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–π")
            return False

        return True

    def verify_data(self) -> None:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        print("\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –≤–∞–∫–∞–Ω—Å–∏–π
        companies = self.db_manager.get_companies_and_vacancies_count()
        if companies:
            print(f"\n‚úì –ö–æ–º–ø–∞–Ω–∏–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö ({len(companies)}):")
            for i, company in enumerate(companies[:5], 1):
                print(f"  {i}. {company['company_name']}: {company['vacancies_count']} –≤–∞–∫–∞–Ω—Å–∏–π")
            if len(companies) > 5:
                print(f"  ... –∏ –µ—â–µ {len(companies) - 5} –∫–æ–º–ø–∞–Ω–∏–π")

        # –°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞
        avg_salary = self.db_manager.get_avg_salary()
        if avg_salary:
            print(f"\nüí∞ –°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞: {avg_salary:,.0f} —Ä—É–±.")

        # –ü—Ä–∏–º–µ—Ä—ã –≤–∞–∫–∞–Ω—Å–∏–π —Å Python
        python_vacancies = self.db_manager.get_vacancies_with_keyword("python")
        if python_vacancies:
            print(f"\nüêç –ù–∞–π–¥–µ–Ω–æ Python –≤–∞–∫–∞–Ω—Å–∏–π: {len(python_vacancies)}")
            for vacancy in python_vacancies[:3]:
                salary_info = ""
                if vacancy.get('salary_from') or vacancy.get('salary_to'):
                    if vacancy.get('salary_from'):
                        salary_info = f" (–æ—Ç {vacancy['salary_from']:,} —Ä—É–±.)"
                print(f"  ‚Ä¢ {vacancy['vacancy_name']} –≤ {vacancy['company_name']}{salary_info}")

    def run_full_process(self, use_cache: bool = True) -> bool:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.

        Args:
            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã

        Returns:
            bool: True –µ—Å–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ
        """
        print("=" * 60)
        print("–ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• HEADHUNTER –í POSTGRESQL")
        print("=" * 60)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ë–î
        if not self.setup_database():
            return False

        # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        data = self.collect_data(use_cache)
        if not data:
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
            return False

        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –ë–î
        if not self.load_to_database(data):
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.verify_data()

        print("\n" + "=" * 60)
        print("‚úì –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print("=" * 60)

        return True

    def run_full_process_with_params(self, use_cache: bool = True, keyword: str = None, period: int = 15) -> bool:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.

        Args:
            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞
            period: –ü–µ—Ä–∏–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–π –≤ –¥–Ω—è—Ö

        Returns:
            bool: True –µ—Å–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ
        """
        print("=" * 60)
        print("–ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• HEADHUNTER –í POSTGRESQL")
        print("=" * 60)

        # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤–Ω—É—Ç—Ä–∏ collect_data)
        data = self.collect_data(use_cache, keyword, period)
        if not data:
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
            return False

        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –ë–î —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        new_companies = [c for c in data.get('companies', []) 
                        if c.get('id') not in self.db_manager.get_existing_company_ids()]
        existing_vacancy_ids = self.db_manager.get_existing_vacancy_ids()
        new_vacancies = [v for v in data.get('vacancies', []) 
                        if v.get('id') not in existing_vacancy_ids]

        if new_companies or new_vacancies:
            filtered_data = {
                'companies': new_companies,
                'vacancies': new_vacancies
            }
            
            if not self.load_to_database(filtered_data):
                return False
        else:
            print("‚úì –ù–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.verify_data()

        print("\n" + "=" * 60)
        print("‚úì –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print("=" * 60)

        return True


    def clear_cache(self) -> bool:
        """
        –û—á–∏—â–∞–µ—Ç –∫—ç—à –¥–∞–Ω–Ω—ã—Ö.

        Returns:
            bool: True –µ—Å–ª–∏ –∫—ç—à —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω
        """
        try:
            files_to_remove = [self.cache_file, self.cache_meta_file]
            removed_count = 0

            for file_path in files_to_remove:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    removed_count += 1

            if removed_count > 0:
                print(f"üóëÔ∏è –ö—ç—à –æ—á–∏—â–µ–Ω ({removed_count} —Ñ–∞–π–ª–æ–≤ —É–¥–∞–ª–µ–Ω–æ)")
                return True
            else:
                print("üìÇ –ö—ç—à —É–∂–µ –ø—É—Å—Ç")
                return False

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞: {e}")
            return False

    def get_cache_info(self) -> Dict:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫—ç—à–µ.

        Returns:
            Dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫—ç—à–µ
        """
        info = {
            'exists': os.path.exists(self.cache_file),
            'valid': False,
            'size_mb': 0,
            'created_at': None,
            'companies_count': 0,
            'vacancies_count': 0
        }

        if info['exists']:
            try:
                # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                size_bytes = os.path.getsize(self.cache_file)
                info['size_mb'] = round(size_bytes / (1024 * 1024), 2)

                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = self.load_cache_metadata()
                if metadata:
                    info['created_at'] = metadata.get('created_at')
                    info['companies_count'] = metadata.get('companies_count', 0)
                    info['vacancies_count'] = metadata.get('vacancies_count', 0)

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
                info['valid'] = self.is_cache_valid()

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫—ç—à–µ: {e}")

        return info

    def load_data(self, use_cache: bool = True) -> bool:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è UI).
        
        Args:
            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            
        Returns:
            bool: True –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
        """
        return self.run_full_process(use_cache)

    def load_data_with_params(self, use_cache: bool = True, keyword: str = None, period: int = 15) -> bool:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è UI).
        
        Args:
            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞
            period: –ü–µ—Ä–∏–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–π –≤ –¥–Ω—è—Ö
            
        Returns:
            bool: True –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
        """
        return self.run_full_process_with_params(use_cache, keyword, period)