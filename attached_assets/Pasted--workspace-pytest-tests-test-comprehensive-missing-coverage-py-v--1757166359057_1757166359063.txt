~/workspace$ pytest tests/test_comprehensive_missing_coverage.py -v
============================== test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.2, pluggy-1.6.0 -- /nix/store/2lcqw1d28vklbk8ikiwad28iq2smwndv-python-wrapped-0.1.0/bin/python3
cachedir: .pytest_cache
rootdir: /home/runner/workspace
configfile: pyproject.toml
plugins: cov-6.2.1, mock-3.15.0
collected 29 items                                                              

tests/test_comprehensive_missing_coverage.py::TestDBManagerCoverage::test_get_companies_and_vacancies_count_success FAILED [  3%]
tests/test_comprehensive_missing_coverage.py::TestDBManagerCoverage::test_get_companies_and_vacancies_count_error PASSED [  6%]
tests/test_comprehensive_missing_coverage.py::TestDBManagerCoverage::test_get_all_vacancies_success PASSED [ 10%]
tests/test_comprehensive_missing_coverage.py::TestDBManagerCoverage::test_database_connection_handling PASSED [ 13%]
tests/test_comprehensive_missing_coverage.py::TestDBManagerCoverage::test_query_execution_methods PASSED [ 17%]
tests/test_comprehensive_missing_coverage.py::TestPostgresSaverCoverage::test_get_vacancies_with_results PASSED [ 20%]
tests/test_comprehensive_missing_coverage.py::TestPostgresSaverCoverage::test_save_vacancies_single_vacancy FAILED [ 24%]
tests/test_comprehensive_missing_coverage.py::TestPostgresSaverCoverage::test_delete_vacancy_by_id_success FAILED [ 27%]
tests/test_comprehensive_missing_coverage.py::TestPostgresSaverCoverage::test_error_handling_in_save_operations FAILED [ 31%]
tests/test_comprehensive_missing_coverage.py::TestPostgresSaverCoverage::test_batch_operations FAILED [ 34%]
tests/test_comprehensive_missing_coverage.py::TestSimpleDBAdapterCoverage::test_adapter_initialization_with_different_urls PASSED [ 37%]
tests/test_comprehensive_missing_coverage.py::TestSimpleDBAdapterCoverage::test_query_execution PASSED [ 41%]
tests/test_comprehensive_missing_coverage.py::TestSimpleDBAdapterCoverage::test_connection_management PASSED [ 44%]
tests/test_comprehensive_missing_coverage.py::TestSimpleDBAdapterCoverage::test_transaction_handling PASSED [ 48%]
tests/test_comprehensive_missing_coverage.py::TestFileCacheCoverage::test_cache_basic_operations PASSED [ 51%]
tests/test_comprehensive_missing_coverage.py::TestFileCacheCoverage::test_cache_expiration PASSED [ 55%]
tests/test_comprehensive_missing_coverage.py::TestFileCacheCoverage::test_cache_cleanup_operations PASSED [ 58%]
tests/test_comprehensive_missing_coverage.py::TestFileCacheCoverage::test_cache_statistics PASSED [ 62%]
tests/test_comprehensive_missing_coverage.py::TestStorageFactoryCoverage::test_factory_creation_methods PASSED [ 65%]
tests/test_comprehensive_missing_coverage.py::TestStorageFactoryCoverage::test_factory_with_configuration PASSED [ 68%]
tests/test_comprehensive_missing_coverage.py::TestStorageFactoryCoverage::test_factory_registration_system PASSED [ 72%]
tests/test_comprehensive_missing_coverage.py::TestEnvLoaderCoverage::test_env_loader_initialization PASSED [ 75%]
tests/test_comprehensive_missing_coverage.py::TestEnvLoaderCoverage::test_environment_variable_loading PASSED [ 79%]
tests/test_comprehensive_missing_coverage.py::TestEnvLoaderCoverage::test_variable_access_methods PASSED [ 82%]
tests/test_comprehensive_missing_coverage.py::TestEnvLoaderCoverage::test_validation_methods PASSED [ 86%]
tests/test_comprehensive_missing_coverage.py::TestUIConfigCoverage::test_ui_config_initialization PASSED [ 89%]
tests/test_comprehensive_missing_coverage.py::TestUIConfigCoverage::test_pagination_config PASSED [ 93%]
tests/test_comprehensive_missing_coverage.py::TestUIConfigCoverage::test_ui_config_methods PASSED [ 96%]
tests/test_comprehensive_missing_coverage.py::TestUIConfigCoverage::test_config_validation PASSED [100%]

=================================== FAILURES ====================================
_____ TestDBManagerCoverage.test_get_companies_and_vacancies_count_success ______

self = <Mock name='mock.execute' id='140395216504016'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'execute' to have been called.

/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/unittest/mock.py:908: AssertionError

During handling of the above exception, another exception occurred:

self = <tests.test_comprehensive_missing_coverage.TestDBManagerCoverage object at 0x7fb04f514090>
mock_connect = <MagicMock name='connect' id='140395216417360'>
db_manager = <src.storage.db_manager.DBManager object at 0x7fb04f4c44d0>
mock_connection = (<Mock name='connect()' id='140395223646800'>, <Mock id='140395223595152'>)

    @patch('psycopg2.connect')
    def test_get_companies_and_vacancies_count_success(self, mock_connect, db_manager, mock_connection):
        """Тест успешного получения списка компаний и количества вакансий"""
        if not DB_MANAGER_AVAILABLE:
            return
    
        mock_conn, mock_cursor = mock_connection
        mock_connect.return_value = mock_conn
        mock_cursor.fetchall.return_value = [
            ('TechCorp', 50),
            ('DataCorp', 30),
            ('WebCorp', 25)
        ]
    
        with patch.object(db_manager, '_get_connection', return_value=mock_conn):
            result = db_manager.get_companies_and_vacancies_count()
    
        assert isinstance(result, list)
        # DBManager возвращает список по умолчанию при отсутствии подключения
>       mock_cursor.execute.assert_called()
E       AssertionError: Expected 'execute' to have been called.

tests/test_comprehensive_missing_coverage.py:111: AssertionError
------------------------------- Captured log call -------------------------------
ERROR    src.storage.db_manager:db_manager.py:855 Ошибка подключения к БД: 'Mock' object does not support the context manager protocol
WARNING  src.storage.db_manager:db_manager.py:373 Нет подключения к базе данных
_________ TestPostgresSaverCoverage.test_save_vacancies_single_vacancy __________

self = <tests.test_comprehensive_missing_coverage.TestPostgresSaverCoverage object at 0x7fb04f005e90>
mock_connect = <MagicMock name='connect' id='140395216518160'>
postgres_saver = <src.storage.postgres_saver.PostgresSaver object at 0x7fb04f4f9a10>
mock_vacancy = <src.vacancies.models.Vacancy object at 0x7fb04f907380>

    @patch('psycopg2.connect')
    def test_save_vacancies_single_vacancy(self, mock_connect, postgres_saver, mock_vacancy):
        """Тест сохранения одной вакансии"""
        if not POSTGRES_SAVER_AVAILABLE:
            return
    
        mock_conn = Mock()
        mock_cursor = Mock()
        mock_conn.cursor.return_value.__enter__ = Mock(return_value=mock_cursor)
        mock_conn.cursor.return_value.__exit__ = Mock(return_value=None)
        mock_connect.return_value = mock_conn
    
        with patch.object(postgres_saver, '_get_connection', return_value=mock_conn):
            mock_cursor.fetchall.return_value = []  # Пустой список компаний
            mock_cursor.rowcount = 1
    
            # Используем реальный объект Vacancy
>           result = postgres_saver.save_vacancies([mock_vacancy])
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_comprehensive_missing_coverage.py:241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/storage/postgres_saver.py:707: in save_vacancies
    update_messages = self.add_vacancy_batch_optimized(vacancies)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <src.storage.postgres_saver.PostgresSaver object at 0x7fb04f4f9a10>
vacancies = [<src.vacancies.models.Vacancy object at 0x7fb04f907380>]
search_query = None

    def add_vacancy_batch_optimized(
        self, vacancies: Union[Vacancy, List[Vacancy]], search_query: str = None
    ) -> List[str]:
        """
        Максимально оптимизированное batch-добавление вакансий через временные таблицы.
        Использует SQL для всех операций, минимизирует количество запросов.
        """
        if not isinstance(vacancies, list):
            vacancies = [vacancies]
    
        # Исправляем двойную вложенность списков
        if len(vacancies) == 1 and isinstance(vacancies[0], list):
            vacancies = vacancies[0]
            logger.debug(f"Исправлена двойная вложенность списка: получено {len(vacancies)} вакансий")
    
        if not vacancies:
            return []
    
        connection = self._get_connection()
        update_messages: List[str] = []
    
        try:
            cursor = connection.cursor()
    
            # Создаем временную таблицу с такой же структурой как основная таблица vacancies
            cursor.execute(
                """
                CREATE TEMP TABLE temp_new_vacancies AS
                SELECT * FROM vacancies WHERE 1=0
            """
            )
    
            # Получаем сопоставление компаний только по ID
            cursor.execute(
                """
                SELECT id, name, hh_id, sj_id
                FROM companies
            """
            )
    
            company_id_mapping = {}  # hh_id/sj_id -> company_id
    
            results = cursor.fetchall()
>           for row in results:
E           TypeError: 'Mock' object is not iterable

src/storage/postgres_saver.py:373: TypeError
__________ TestPostgresSaverCoverage.test_delete_vacancy_by_id_success __________

self = <tests.test_comprehensive_missing_coverage.TestPostgresSaverCoverage object at 0x7fb04f006510>
mock_connect = <MagicMock name='connect' id='140395212048016'>
postgres_saver = <src.storage.postgres_saver.PostgresSaver object at 0x7fb04f07d490>

    @patch('psycopg2.connect')
    def test_delete_vacancy_by_id_success(self, mock_connect, postgres_saver):
        """Тест успешного удаления вакансии по ID"""
        if not POSTGRES_SAVER_AVAILABLE:
            return
    
        mock_conn = Mock()
        mock_cursor = Mock()
        mock_conn.cursor.return_value.__enter__ = Mock(return_value=mock_cursor)
        mock_conn.cursor.return_value.__exit__ = Mock(return_value=None)
        mock_connect.return_value = mock_conn
    
        with patch.object(postgres_saver, '_get_connection', return_value=mock_conn):
            mock_cursor.rowcount = 1
    
            if hasattr(postgres_saver, 'delete_vacancy_by_id'):
>               result = postgres_saver.delete_vacancy_by_id('test123')
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_comprehensive_missing_coverage.py:261: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <src.storage.postgres_saver.PostgresSaver object at 0x7fb04f07d490>
vacancy_id = 'test123'

    def delete_vacancy_by_id(self, vacancy_id: str) -> bool:
        """Удаляет вакансию по ID"""
        connection = self._get_connection()
        try:
            cursor = connection.cursor()
            cursor.execute("DELETE FROM vacancies WHERE vacancy_id = %s", (vacancy_id,))
    
>           if cursor.rowcount > 0:
               ^^^^^^^^^^^^^^^^^^^
E           TypeError: '>' not supported between instances of 'Mock' and 'int'

src/storage/postgres_saver.py:1001: TypeError
_______ TestPostgresSaverCoverage.test_error_handling_in_save_operations ________

self = <src.storage.postgres_saver.PostgresSaver object at 0x7fb04efcb790>
vacancies = [<src.vacancies.models.Vacancy object at 0x7fb04f23bc70>]
search_query = None

    def add_vacancy_batch_optimized(
        self, vacancies: Union[Vacancy, List[Vacancy]], search_query: str = None
    ) -> List[str]:
        """
        Максимально оптимизированное batch-добавление вакансий через временные таблицы.
        Использует SQL для всех операций, минимизирует количество запросов.
        """
        if not isinstance(vacancies, list):
            vacancies = [vacancies]
    
        # Исправляем двойную вложенность списков
        if len(vacancies) == 1 and isinstance(vacancies[0], list):
            vacancies = vacancies[0]
            logger.debug(f"Исправлена двойная вложенность списка: получено {len(vacancies)} вакансий")
    
        if not vacancies:
            return []
    
        connection = self._get_connection()
        update_messages: List[str] = []
    
        try:
>           cursor = connection.cursor()
                     ^^^^^^^^^^^^^^^^^
E           AttributeError: 'NoneType' object has no attribute 'cursor'

src/storage/postgres_saver.py:352: AttributeError

During handling of the above exception, another exception occurred:

self = <tests.test_comprehensive_missing_coverage.TestPostgresSaverCoverage object at 0x7fb04f006c90>
postgres_saver = <src.storage.postgres_saver.PostgresSaver object at 0x7fb04efcb790>
mock_vacancy = <src.vacancies.models.Vacancy object at 0x7fb04f23bc70>

    def test_error_handling_in_save_operations(self, postgres_saver, mock_vacancy):
        """Тест обработки ошибок при сохранении"""
        if not POSTGRES_SAVER_AVAILABLE:
            return
    
        with patch.object(postgres_saver, '_get_connection', return_value=None):
            # Тест с недоступным подключением
>           result = postgres_saver.save_vacancies([mock_vacancy])
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_comprehensive_missing_coverage.py:271: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/storage/postgres_saver.py:707: in save_vacancies
    update_messages = self.add_vacancy_batch_optimized(vacancies)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <src.storage.postgres_saver.PostgresSaver object at 0x7fb04efcb790>
vacancies = [<src.vacancies.models.Vacancy object at 0x7fb04f23bc70>]
search_query = None

    def add_vacancy_batch_optimized(
        self, vacancies: Union[Vacancy, List[Vacancy]], search_query: str = None
    ) -> List[str]:
        """
        Максимально оптимизированное batch-добавление вакансий через временные таблицы.
        Использует SQL для всех операций, минимизирует количество запросов.
        """
        if not isinstance(vacancies, list):
            vacancies = [vacancies]
    
        # Исправляем двойную вложенность списков
        if len(vacancies) == 1 and isinstance(vacancies[0], list):
            vacancies = vacancies[0]
            logger.debug(f"Исправлена двойная вложенность списка: получено {len(vacancies)} вакансий")
    
        if not vacancies:
            return []
    
        connection = self._get_connection()
        update_messages: List[str] = []
    
        try:
            cursor = connection.cursor()
    
            # Создаем временную таблицу с такой же структурой как основная таблица vacancies
            cursor.execute(
                """
                CREATE TEMP TABLE temp_new_vacancies AS
                SELECT * FROM vacancies WHERE 1=0
            """
            )
    
            # Получаем сопоставление компаний только по ID
            cursor.execute(
                """
                SELECT id, name, hh_id, sj_id
                FROM companies
            """
            )
    
            company_id_mapping = {}  # hh_id/sj_id -> company_id
    
            results = cursor.fetchall()
            for row in results:
                comp_id, name, hh_id, sj_id = row
    
                # Добавляем только ID-маппинги с приведением к строке
                if hh_id:
                    company_id_mapping[str(hh_id)] = comp_id
                if sj_id:
                    company_id_mapping[str(sj_id)] = comp_id
    
            # Подготавливаем данные для вставки/обновления (все переданные вакансии)
            insert_data = []
            vacancy_company_mapping = {}  # Словарь для сохранения соответствия vacancy_id -> company_id
    
            for vacancy in vacancies:
                # Проверяем, что vacancy действительно объект Vacancy
                if not hasattr(vacancy, "employer"):
                    logger.error(f"Объект не является Vacancy: {type(vacancy)} - {vacancy}")
                    continue
    
                # Определяем company_id для связи с таблицей companies
                mapped_company_id = None
                employer_name = None
                employer_id = None
    
                if vacancy.employer:
                    if isinstance(vacancy.employer, dict):
                        employer_name = vacancy.employer.get("name", "").strip()
                        employer_id = vacancy.employer.get("id", "").strip()
                    elif hasattr(vacancy.employer, "get_name"):
                        employer_name = vacancy.employer.get_name().strip()
                        employer_id = getattr(vacancy.employer, "id", "").strip()
                    elif hasattr(vacancy.employer, "name"):
                        employer_name = str(getattr(vacancy.employer, "name", "")).strip()
                        employer_id = str(getattr(vacancy.employer, "id", "")).strip()
                    else:
                        employer_name = str(vacancy.employer).strip()
                        employer_id = ""
    
                # Фильтруем ТОЛЬКО по ID компаний (hh_id и sj_id)
                if employer_id:
                    mapped_company_id = company_id_mapping.get(str(employer_id))
    
                # Сохраняем соответствие и устанавливаем company_id
                if mapped_company_id:
                    vacancy_company_mapping[vacancy.vacancy_id] = mapped_company_id
                    vacancy.company_id = mapped_company_id
                    logger.debug(
                        f"Сопоставлено: '{employer_name}' (ID: {employer_id}) -> company_id: {mapped_company_id}"
                    )
    
            # Обрабатываем ВСЕ переданные вакансии
            for vacancy in vacancies:
                # Проверяем, что vacancy действительно объект Vacancy
                if not hasattr(vacancy, "employer"):
                    logger.error(f"Объект не является Vacancy во втором цикле: {type(vacancy)}")
                    continue
    
                mapped_company_id = vacancy_company_mapping.get(vacancy.vacancy_id, None)
    
                # Безопасная обработка salary
                salary_from = None
                salary_to = None
                salary_currency = None
    
                if vacancy.salary:
                    if hasattr(vacancy.salary, "salary_from"):
                        salary_from = vacancy.salary.salary_from
                        salary_to = vacancy.salary.salary_to
                        salary_currency = vacancy.salary.currency
                    elif isinstance(vacancy.salary, dict):
                        salary_from = vacancy.salary.get("from")
                        salary_to = vacancy.salary.get("to")
                        salary_currency = vacancy.salary.get("currency")
                    # Если salary - boolean или что-то другое, оставляем None
    
                # Конвертируем employer в строку для сохранения в БД
                employer_str = None
                if vacancy.employer:
                    if isinstance(vacancy.employer, dict):
                        employer_str = vacancy.employer.get("name", str(vacancy.employer))
                    elif hasattr(vacancy.employer, "get_name"):
                        employer_str = vacancy.employer.get_name()
                    elif hasattr(vacancy.employer, "name"):
                        employer_str = str(getattr(vacancy.employer, "name", ""))
                    else:
                        employer_str = str(vacancy.employer)
    
                # Унифицированная обработка area для сохранения в БД
                try:
                    from utils.data_normalizers import normalize_area_data
                except ImportError:
                    from src.utils.data_normalizers import normalize_area_data
                area_str = normalize_area_data(vacancy.area)
    
                # Обработка полей объектов в строки для БД
                experience_str = None
                if vacancy.experience:
                    if hasattr(vacancy.experience, "get_name"):
                        experience_str = vacancy.experience.get_name()
                    else:
                        experience_str = str(vacancy.experience)
    
                employment_str = None
                if vacancy.employment:
                    if hasattr(vacancy.employment, "get_name"):
                        employment_str = vacancy.employment.get_name()
                    else:
                        employment_str = str(vacancy.employment)
    
                schedule_str = None
                if vacancy.schedule:
                    if hasattr(vacancy.schedule, "get_name"):
                        schedule_str = vacancy.schedule.get_name()
                    else:
                        schedule_str = str(vacancy.schedule)
    
                # Обработка даты published_at
                published_date = self._normalize_published_date(vacancy.published_at)
    
                insert_data.append(
                    (
                        vacancy.vacancy_id,
                        vacancy.title,
                        vacancy.url,
                        salary_from,
                        salary_to,
                        salary_currency,
                        vacancy.description,
                        vacancy.requirements,
                        vacancy.responsibilities,
                        experience_str,
                        employment_str,
                        schedule_str,
                        area_str,
                        vacancy.source,
                        published_date,
                        mapped_company_id,  # Всегда будет не None для целевых компаний
                        search_query,
                    )
                )
    
            # Bulk insert во временную таблицу
            from psycopg2.extras import execute_values
    
            execute_values(
                cursor,
                """INSERT INTO temp_new_vacancies (
                    vacancy_id, title, url, salary_from, salary_to, salary_currency,
                    description, requirements, responsibilities, experience,
                    employment, schedule, area, source, published_at, company_id, search_query
                ) VALUES %s""",
                insert_data,
                template=None,
                page_size=1000,
            )
    
            # Находим новые вакансии (которых нет в основной таблице)
            cursor.execute(
                """
                INSERT INTO vacancies (
                    vacancy_id, title, url, salary_from, salary_to, salary_currency,
                    description, requirements, responsibilities, experience,
                    employment, schedule, area, source, published_at, company_id, search_query
                )
                SELECT t.vacancy_id, t.title, t.url, t.salary_from, t.salary_to, t.salary_currency,
                       t.description, t.requirements, t.responsibilities, t.experience,
                       t.employment, t.schedule, t.area, t.source, t.published_at, t.company_id, t.search_query
                FROM temp_new_vacancies t
                LEFT JOIN vacancies v ON t.vacancy_id = v.vacancy_id
                WHERE v.vacancy_id IS NULL
            """
            )
    
            new_count = cursor.rowcount
    
            # Находим и обновляем существующие вакансии с изменениями
            cursor.execute(
                """
                UPDATE vacancies v SET
                    title = t.title,
                    url = t.url,
                    description = t.description,
                    experience = t.experience,
                    employment = t.employment,
                    schedule = t.schedule,
                    area = t.area,
                    source = t.source,
                    published_at = t.published_at,
                    company_id = t.company_id,
                    updated_at = CURRENT_TIMESTAMP
                FROM temp_new_vacancies t
                WHERE v.vacancy_id = t.vacancy_id
                AND (
                    v.title != t.title OR
                    v.url != t.url OR
                    v.description != t.description OR
                    COALESCE(v.salary_from, 0) != COALESCE(t.salary_from, 0) OR
                    COALESCE(v.salary_to, 0) != COALESCE(t.salary_to, 0) OR
                    COALESCE(v.salary_currency, '') != COALESCE(t.salary_currency, '') OR
                    COALESCE(v.company_id::text, '') IS DISTINCT FROM COALESCE(t.company_id::text, '') -- Приведение к text для сравнения
                )
            """
            )
    
            updated_count = cursor.rowcount
    
            # Получаем информацию о добавленных и обновленных вакансиях для сообщений
            cursor.execute(
                """
                SELECT t.vacancy_id, t.title,
                       CASE WHEN v.vacancy_id IS NULL THEN 'new' ELSE 'updated' END as action
                FROM temp_new_vacancies t
                LEFT JOIN vacancies v ON t.vacancy_id = v.vacancy_id
                ORDER BY action, t.vacancy_id
                LIMIT 10
            """
            )
    
            results = cursor.fetchall()
            for row in results:
                # Используем индексы вместо ключей для обычного cursor
                vacancy_id, title, action = row[0], row[1], row[2]
                if action == "new":
                    update_messages.append(f"Добавлена новая вакансия ID {vacancy_id}: '{title}'")
                else:
                    update_messages.append(f"Вакансия ID {vacancy_id} обновлена: '{title}'")
    
            # Добавляем сводку если много операций
            total_processed = len(vacancies)
            if total_processed > 10:
                if new_count > 5:
                    update_messages.append(f"... и еще {new_count - 5} новых вакансий")
                if updated_count > 5:
                    update_messages.append(f"... и еще {updated_count - 5} обновленных вакансий")
    
            connection.commit()
    
            total_input = len(vacancies)
    
            logger.info("Batch операция через временные таблицы:")
            logger.info(f"  Входящих вакансий: {total_input}")
            logger.info(f"  Добавлено в БД: {new_count}")
            logger.info(f"  Обновлено в БД: {updated_count}")
    
            # Дополнительная проверка количества записей в БД
            cursor.execute("SELECT COUNT(*) FROM vacancies")
            total_in_db = cursor.fetchone()[0]
            logger.info(f"  Итого записей в БД после операции: {total_in_db}")
    
            # Показываем сводку результатов
            logger.info(
                f"Результат: сохранено {new_count + updated_count} из {total_input} вакансий (новых: {new_count}, обновлено: {updated_count})"
            )
    
        except PsycopgError as e:
            logger.error(f"Ошибка при batch операции через временные таблицы: {e}")
            if not connection.closed:
                try:
                    connection.rollback()
                except Exception:
                    pass
            raise
        finally:
            if "cursor" in locals():
                cursor.close()
>           connection.close()
            ^^^^^^^^^^^^^^^^
E           AttributeError: 'NoneType' object has no attribute 'close'

src/storage/postgres_saver.py:638: AttributeError
________________ TestPostgresSaverCoverage.test_batch_operations ________________

self = <tests.test_comprehensive_missing_coverage.TestPostgresSaverCoverage object at 0x7fb04f007390>
postgres_saver = <src.storage.postgres_saver.PostgresSaver object at 0x7fb04f093b50>

    def test_batch_operations(self, postgres_saver):
        """Тест пакетных операций"""
        if not POSTGRES_SAVER_AVAILABLE:
            return
    
        # Создаем набор тестовых вакансий
        test_vacancies = []
        for i in range(5):
            vacancy_data = {
                'vacancy_id': f'test{i}',
                'title': f'Job {i}',
                'url': f'https://test{i}.com',
                'description': f'Description {i}',
                'employer': {'name': f'Company {i}', 'employer_id': f'comp{i}'},
                'salary': {'from': 100000, 'to': 150000, 'currency': 'RUR'},
                'source': 'test'
            }
            test_vacancies.append(vacancy_data)
    
        # Мокаем соединение для пакетной операции
        with patch.object(postgres_saver, '_get_connection') as mock_conn:
            mock_conn.return_value = Mock()
>           result = postgres_saver.save_vacancies(test_vacancies)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_comprehensive_missing_coverage.py:296: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src/storage/postgres_saver.py:707: in save_vacancies
    update_messages = self.add_vacancy_batch_optimized(vacancies)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <src.storage.postgres_saver.PostgresSaver object at 0x7fb04f093b50>
vacancies = [{'description': 'Description 0', 'employer': {'employer_id': 'comp0', 'name': 'Company 0'}, 'salary': {'currency': 'R...d': 'comp4', 'name': 'Company 4'}, 'salary': {'currency': 'RUR', 'from': 100000, 'to': 150000}, 'source': 'test', ...}]
search_query = None

    def add_vacancy_batch_optimized(
        self, vacancies: Union[Vacancy, List[Vacancy]], search_query: str = None
    ) -> List[str]:
        """
        Максимально оптимизированное batch-добавление вакансий через временные таблицы.
        Использует SQL для всех операций, минимизирует количество запросов.
        """
        if not isinstance(vacancies, list):
            vacancies = [vacancies]
    
        # Исправляем двойную вложенность списков
        if len(vacancies) == 1 and isinstance(vacancies[0], list):
            vacancies = vacancies[0]
            logger.debug(f"Исправлена двойная вложенность списка: получено {len(vacancies)} вакансий")
    
        if not vacancies:
            return []
    
        connection = self._get_connection()
        update_messages: List[str] = []
    
        try:
            cursor = connection.cursor()
    
            # Создаем временную таблицу с такой же структурой как основная таблица vacancies
            cursor.execute(
                """
                CREATE TEMP TABLE temp_new_vacancies AS
                SELECT * FROM vacancies WHERE 1=0
            """
            )
    
            # Получаем сопоставление компаний только по ID
            cursor.execute(
                """
                SELECT id, name, hh_id, sj_id
                FROM companies
            """
            )
    
            company_id_mapping = {}  # hh_id/sj_id -> company_id
    
            results = cursor.fetchall()
>           for row in results:
E           TypeError: 'Mock' object is not iterable

src/storage/postgres_saver.py:373: TypeError
============================ short test summary info ============================
FAILED tests/test_comprehensive_missing_coverage.py::TestDBManagerCoverage::test_get_companies_and_vacancies_count_success - AssertionError: Expected 'execute' to have been called.
FAILED tests/test_comprehensive_missing_coverage.py::TestPostgresSaverCoverage::test_save_vacancies_single_vacancy - TypeError: 'Mock' object is not iterable
FAILED tests/test_comprehensive_missing_coverage.py::TestPostgresSaverCoverage::test_delete_vacancy_by_id_success - TypeError: '>' not supported between instances of 'Mock' and 'int'
FAILED tests/test_comprehensive_missing_coverage.py::TestPostgresSaverCoverage::test_error_handling_in_save_operations - AttributeError: 'NoneType' object has no attribute 'close'
FAILED tests/test_comprehensive_missing_coverage.py::TestPostgresSaverCoverage::test_batch_operations - TypeError: 'Mock' object is not iterable
========================= 5 failed, 24 passed in 0.53s ==========================
~/workspace$ 